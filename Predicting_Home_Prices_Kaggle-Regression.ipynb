{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Importing Numpy and Pandas'''\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "'''Machine Learning Packages'''\n",
    "from sklearn.cross_validation import cross_val_predict, cross_val_score \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression,ElasticNetCV, LassoCV, RidgeCV , Ridge, Lasso, LassoLarsIC,  ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectKBest, RFE, RFECV, SelectPercentile\n",
    "\n",
    "'''Preprocessing Packages'''\n",
    "from sklearn.preprocessing import StandardScaler, Imputer, PolynomialFeatures,Binarizer, OneHotEncoder, LabelEncoder\n",
    "\n",
    "\n",
    "'''Plotting Packages'''\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_selection import SelectPercentile, SelectKBest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Test and the Train Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Loading the CSV into the training and the testing dataframe'''\n",
    "train_raw = pd.read_csv('train.csv')\n",
    "test_raw = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Replacing the spaces in the column names with the _'''\n",
    "train_raw.columns = train_raw.columns.str.replace(' ', '')\n",
    "test_raw.columns = test_raw.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PID</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>533352170</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13517</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>130500</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>544</td>\n",
       "      <td>531379050</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>11492</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>220000</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id        PID MSSubClass MSZoning  LotFrontage  LotArea Street Alley  \\\n",
       "0  109  533352170         60       RL          NaN    13517   Pave   NaN   \n",
       "1  544  531379050         60       RL         43.0    11492   Pave   NaN   \n",
       "\n",
       "  LotShape LandContour  ...   PoolQC Fence MiscFeature MiscVal MoSold YrSold  \\\n",
       "0      IR1         Lvl  ...      NaN   NaN         NaN       0      3   2010   \n",
       "1      IR1         Lvl  ...      NaN   NaN         NaN       0      4   2009   \n",
       "\n",
       "  SaleType SaleCondition  SalePrice source  \n",
       "0      WD         Normal     130500  Train  \n",
       "1      WD         Normal     220000  Train  \n",
       "\n",
       "[2 rows x 83 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Validating the training dataset'''\n",
    "train_raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PID</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2658</td>\n",
       "      <td>902301120</td>\n",
       "      <td>190</td>\n",
       "      <td>RM</td>\n",
       "      <td>69.0</td>\n",
       "      <td>9142</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2718</td>\n",
       "      <td>905108090</td>\n",
       "      <td>90</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9662</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id        PID MSSubClass MSZoning  LotFrontage  LotArea Street Alley  \\\n",
       "0  2658  902301120        190       RM         69.0     9142   Pave  Grvl   \n",
       "1  2718  905108090         90       RL          NaN     9662   Pave   NaN   \n",
       "\n",
       "  LotShape LandContour  ...   ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
       "0      Reg         Lvl  ...             0        0    NaN   NaN         NaN   \n",
       "1      IR1         Lvl  ...             0        0    NaN   NaN         NaN   \n",
       "\n",
       "  MiscVal MoSold YrSold  SaleType source  \n",
       "0       0      4   2006       WD    Test  \n",
       "1       0      8   2006       WD    Test  \n",
       "\n",
       "[2 rows x 81 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Validating the test dataset'''\n",
    "test_raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PID</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>533352170</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13517</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>130500</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>544</td>\n",
       "      <td>531379050</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>11492</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>220000</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id        PID MSSubClass MSZoning  LotFrontage  LotArea Street Alley  \\\n",
       "0  109  533352170         60       RL          NaN    13517   Pave   NaN   \n",
       "1  544  531379050         60       RL         43.0    11492   Pave   NaN   \n",
       "\n",
       "  LotShape LandContour  ...   PoolQC Fence MiscFeature MiscVal MoSold YrSold  \\\n",
       "0      IR1         Lvl  ...      NaN   NaN         NaN       0      3   2010   \n",
       "1      IR1         Lvl  ...      NaN   NaN         NaN       0      4   2009   \n",
       "\n",
       "  SaleType SaleCondition  SalePrice source  \n",
       "0      WD         Normal     130500  Train  \n",
       "1      WD         Normal     220000  Train  \n",
       "\n",
       "[2 rows x 83 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Adding a source column in the training dataset'''\n",
    "\n",
    "train_raw['source'] = 'Train'\n",
    "train_raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PID</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2658</td>\n",
       "      <td>902301120</td>\n",
       "      <td>190</td>\n",
       "      <td>RM</td>\n",
       "      <td>69.0</td>\n",
       "      <td>9142</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2718</td>\n",
       "      <td>905108090</td>\n",
       "      <td>90</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9662</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id        PID MSSubClass MSZoning  LotFrontage  LotArea Street Alley  \\\n",
       "0  2658  902301120        190       RM         69.0     9142   Pave  Grvl   \n",
       "1  2718  905108090         90       RL          NaN     9662   Pave   NaN   \n",
       "\n",
       "  LotShape LandContour  ...   ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
       "0      Reg         Lvl  ...             0        0    NaN   NaN         NaN   \n",
       "1      IR1         Lvl  ...             0        0    NaN   NaN         NaN   \n",
       "\n",
       "  MiscVal MoSold YrSold  SaleType source  \n",
       "0       0      4   2006       WD    Test  \n",
       "1       0      8   2006       WD    Test  \n",
       "\n",
       "[2 rows x 81 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Adding a source column in the test dataset'''\n",
    "\n",
    "test_raw['source'] = 'Test'\n",
    "test_raw.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Converting MSSubClass and OverallCond to String'''\n",
    "\n",
    "train_raw['MSSubClass'] = train_raw['MSSubClass'].astype(str)\n",
    "test_raw['MSSubClass'] = test_raw['MSSubClass'].astype(str)\n",
    "train_raw['OverallCond'] = train_raw['OverallCond'].astype(str)\n",
    "test_raw['OverallCond'] = test_raw['OverallCond'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>Alley</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>Street</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemod/Add</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>725</td>\n",
       "      <td>754</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>533.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>6</td>\n",
       "      <td>725.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>0</td>\n",
       "      <td>1976</td>\n",
       "      <td>2005</td>\n",
       "      <td>2010</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>913</td>\n",
       "      <td>1209</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>637.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>8</td>\n",
       "      <td>913.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>0</td>\n",
       "      <td>1996</td>\n",
       "      <td>1997</td>\n",
       "      <td>2009</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch Alley  BedroomAbvGr BldgType BsmtCond  \\\n",
       "0       725       754          0   NaN             3     1Fam       TA   \n",
       "1       913      1209          0   NaN             4     1Fam       TA   \n",
       "\n",
       "  BsmtExposure  BsmtFinSF1  BsmtFinSF2  ...   ScreenPorch Street  \\\n",
       "0           No       533.0         0.0  ...             0   Pave   \n",
       "1           No       637.0         0.0  ...             0   Pave   \n",
       "\n",
       "   TotRmsAbvGrd  TotalBsmtSF Utilities  WoodDeckSF YearBuilt YearRemod/Add  \\\n",
       "0             6        725.0    AllPub           0      1976          2005   \n",
       "1             8        913.0    AllPub           0      1996          1997   \n",
       "\n",
       "  YrSold source  \n",
       "0   2010  Train  \n",
       "1   2009  Train  \n",
       "\n",
       "[2 rows x 83 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Merging the Training and the Test Dataset before creating the dummies'''\n",
    "train_test_merged = train_raw.append(test_raw)\n",
    "train_test_merged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Train    2051\n",
       "Test      879\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Validating the count of the Train and Test Records in the Merged Dataframe \n",
    "Note: This column was added manually to deal with the mutually exclusive class categories in the training and the test dataset\n",
    "'''\n",
    "train_test_merged.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing the list of non-null columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2930 entries, 0 to 878\n",
      "Data columns (total 83 columns):\n",
      "1stFlrSF         2930 non-null int64\n",
      "2ndFlrSF         2930 non-null int64\n",
      "3SsnPorch        2930 non-null int64\n",
      "Alley            198 non-null object\n",
      "BedroomAbvGr     2930 non-null int64\n",
      "BldgType         2930 non-null object\n",
      "BsmtCond         2850 non-null object\n",
      "BsmtExposure     2847 non-null object\n",
      "BsmtFinSF1       2929 non-null float64\n",
      "BsmtFinSF2       2929 non-null float64\n",
      "BsmtFinType1     2850 non-null object\n",
      "BsmtFinType2     2849 non-null object\n",
      "BsmtFullBath     2928 non-null float64\n",
      "BsmtHalfBath     2928 non-null float64\n",
      "BsmtQual         2850 non-null object\n",
      "BsmtUnfSF        2929 non-null float64\n",
      "CentralAir       2930 non-null object\n",
      "Condition1       2930 non-null object\n",
      "Condition2       2930 non-null object\n",
      "Electrical       2929 non-null object\n",
      "EnclosedPorch    2930 non-null int64\n",
      "ExterCond        2930 non-null object\n",
      "ExterQual        2930 non-null object\n",
      "Exterior1st      2930 non-null object\n",
      "Exterior2nd      2930 non-null object\n",
      "Fence            572 non-null object\n",
      "FireplaceQu      1508 non-null object\n",
      "Fireplaces       2930 non-null int64\n",
      "Foundation       2930 non-null object\n",
      "FullBath         2930 non-null int64\n",
      "Functional       2930 non-null object\n",
      "GarageArea       2929 non-null float64\n",
      "GarageCars       2929 non-null float64\n",
      "GarageCond       2771 non-null object\n",
      "GarageFinish     2771 non-null object\n",
      "GarageQual       2771 non-null object\n",
      "GarageType       2773 non-null object\n",
      "GarageYrBlt      2771 non-null float64\n",
      "GrLivArea        2930 non-null int64\n",
      "HalfBath         2930 non-null int64\n",
      "Heating          2930 non-null object\n",
      "HeatingQC        2930 non-null object\n",
      "HouseStyle       2930 non-null object\n",
      "Id               2930 non-null int64\n",
      "KitchenAbvGr     2930 non-null int64\n",
      "KitchenQual      2930 non-null object\n",
      "LandContour      2930 non-null object\n",
      "LandSlope        2930 non-null object\n",
      "LotArea          2930 non-null int64\n",
      "LotConfig        2930 non-null object\n",
      "LotFrontage      2440 non-null float64\n",
      "LotShape         2930 non-null object\n",
      "LowQualFinSF     2930 non-null int64\n",
      "MSSubClass       2930 non-null object\n",
      "MSZoning         2930 non-null object\n",
      "MasVnrArea       2907 non-null float64\n",
      "MasVnrType       2907 non-null object\n",
      "MiscFeature      106 non-null object\n",
      "MiscVal          2930 non-null int64\n",
      "MoSold           2930 non-null int64\n",
      "Neighborhood     2930 non-null object\n",
      "OpenPorchSF      2930 non-null int64\n",
      "OverallCond      2930 non-null object\n",
      "OverallQual      2930 non-null int64\n",
      "PID              2930 non-null int64\n",
      "PavedDrive       2930 non-null object\n",
      "PoolArea         2930 non-null int64\n",
      "PoolQC           13 non-null object\n",
      "RoofMatl         2930 non-null object\n",
      "RoofStyle        2930 non-null object\n",
      "SaleCondition    2051 non-null object\n",
      "SalePrice        2051 non-null float64\n",
      "SaleType         2930 non-null object\n",
      "ScreenPorch      2930 non-null int64\n",
      "Street           2930 non-null object\n",
      "TotRmsAbvGrd     2930 non-null int64\n",
      "TotalBsmtSF      2929 non-null float64\n",
      "Utilities        2930 non-null object\n",
      "WoodDeckSF       2930 non-null int64\n",
      "YearBuilt        2930 non-null int64\n",
      "YearRemod/Add    2930 non-null int64\n",
      "YrSold           2930 non-null int64\n",
      "source           2930 non-null object\n",
      "dtypes: float64(12), int64(25), object(46)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_test_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right away we noticed that there are handful of columns that have null values. This will require some level of handling (e.g. Imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Dropping columns that have very little non-null values '''\n",
    "\n",
    "cols_not_needed_for_regression = ['Alley', 'Fence', 'PoolQC', 'MiscFeature']\n",
    "train_test_merged.drop(cols_not_needed_for_regression,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Review of the Correlation of the predictor variables with the Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage',\n",
       " 'LotArea',\n",
       " 'OverallQual',\n",
       " 'YearBuilt',\n",
       " 'YearRemod/Add',\n",
       " 'MasVnrArea',\n",
       " 'BsmtFinSF1',\n",
       " 'BsmtFinSF2',\n",
       " 'BsmtUnfSF',\n",
       " 'TotalBsmtSF',\n",
       " '1stFlrSF',\n",
       " '2ndFlrSF',\n",
       " 'GrLivArea',\n",
       " 'BsmtFullBath',\n",
       " 'FullBath',\n",
       " 'HalfBath',\n",
       " 'BedroomAbvGr',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Fireplaces',\n",
       " 'GarageYrBlt',\n",
       " 'GarageCars',\n",
       " 'GarageArea',\n",
       " 'WoodDeckSF',\n",
       " 'OpenPorchSF',\n",
       " '3SsnPorch',\n",
       " 'ScreenPorch',\n",
       " 'PoolArea',\n",
       " 'MoSold']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Code below looks at the correlation of the individual predictor variables with the target variables, and also lists out the predictors that have a positive correlation with the target variables'''\n",
    "\n",
    "traindata_corr = train_raw.corr()['SalePrice'][:-1]\n",
    "positively_corelated = traindata_corr[traindata_corr.sort_values(ascending=False)>0]\n",
    "positively_corelated_columns= list(positively_corelated.index)\n",
    "positively_corelated_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of Predictors that have a high level of correlation with the target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OverallQual      0.800207\n",
       "GrLivArea        0.697038\n",
       "GarageArea       0.650270\n",
       "GarageCars       0.648220\n",
       "TotalBsmtSF      0.628925\n",
       "1stFlrSF         0.618486\n",
       "YearBuilt        0.571849\n",
       "YearRemod/Add    0.550370\n",
       "FullBath         0.537969\n",
       "GarageYrBlt      0.533922\n",
       "MasVnrArea       0.512230\n",
       "TotRmsAbvGrd     0.504014\n",
       "Fireplaces       0.471093\n",
       "BsmtFinSF1       0.423519\n",
       "LotFrontage      0.341842\n",
       "OpenPorchSF      0.333476\n",
       "WoodDeckSF       0.326490\n",
       "LotArea          0.296566\n",
       "BsmtFullBath     0.283662\n",
       "HalfBath         0.283001\n",
       "2ndFlrSF         0.248452\n",
       "BsmtUnfSF        0.190210\n",
       "BedroomAbvGr     0.137067\n",
       "ScreenPorch      0.134581\n",
       "3SsnPorch        0.048732\n",
       "MoSold           0.032735\n",
       "PoolArea         0.023106\n",
       "BsmtFinSF2       0.016255\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positively_corelated.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape:  (2051, 83)\n",
      "Testing Shape:  (879, 81)\n",
      "Merge Shape:  (2930, 83)\n"
     ]
    }
   ],
   "source": [
    "'''Validating the Shape of the Training, Test and the Merged Dataframes'''\n",
    "\n",
    "print ('Training Shape: ', train_raw.shape)\n",
    "print ('Testing Shape: ', test_raw.shape)\n",
    "print ('Merge Shape: ', train_test_merged.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is necessary to confirm/validate that all the data manipulations has not convulated the dataset. We notice that, the test dataset has two columns less. This is because the test dataset does not contain the SalePrice and the SaleCondition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of Null Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alley',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinSF1',\n",
       " 'BsmtFinSF2',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'BsmtFullBath',\n",
       " 'BsmtHalfBath',\n",
       " 'BsmtQual',\n",
       " 'BsmtUnfSF',\n",
       " 'Electrical',\n",
       " 'Fence',\n",
       " 'FireplaceQu',\n",
       " 'GarageArea',\n",
       " 'GarageCars',\n",
       " 'GarageCond',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageType',\n",
       " 'GarageYrBlt',\n",
       " 'LotFrontage',\n",
       " 'MasVnrArea',\n",
       " 'MasVnrType',\n",
       " 'MiscFeature',\n",
       " 'PoolQC',\n",
       " 'SaleCondition',\n",
       " 'SalePrice',\n",
       " 'TotalBsmtSF']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Retrieving the list of null columns from the merged Dataset'''\n",
    "null_col_list = list(train_test_merged.columns[train_test_merged.isnull().sum()>0])\n",
    "null_col_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Count of Null Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Null Columns:  29\n"
     ]
    }
   ],
   "source": [
    "'''Getting the count of total number of null columns'''\n",
    "print ('Number of Null Columns: ', len(null_col_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Count of Numeric and Non-Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''This step is to count the number of the Numeric and Non-Numeric columns'''\n",
    "# object_col_count = 0 \n",
    "# numeric_col_count = 0 \n",
    "\n",
    "\n",
    "# for col_type in train_test_merged.dtypes: \n",
    "#     if col_type ==np.object: \n",
    "#         object_col_count += 1 \n",
    "#     elif col_type == np.int64 or col_type == np.float64: \n",
    "#         numeric_col_count += 1\n",
    "#     else: \n",
    "#         continue\n",
    "\n",
    "# print ('Object Col Count: ', object_col_count)\n",
    "# print ('Numberic Col Count: ', numeric_col_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of type Object:\n",
      "\n",
      " ['Alley', 'BldgType', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', 'CentralAir', 'Condition1', 'Condition2', 'Electrical', 'ExterCond', 'ExterQual', 'Exterior1st', 'Exterior2nd', 'Fence', 'FireplaceQu', 'Foundation', 'Functional', 'GarageCond', 'GarageFinish', 'GarageQual', 'GarageType', 'Heating', 'HeatingQC', 'HouseStyle', 'KitchenQual', 'LandContour', 'LandSlope', 'LotConfig', 'LotShape', 'MSSubClass', 'MSZoning', 'MasVnrType', 'MiscFeature', 'Neighborhood', 'OverallCond', 'PavedDrive', 'PoolQC', 'RoofMatl', 'RoofStyle', 'SaleCondition', 'SaleType', 'Street', 'Utilities', 'source']\n",
      "\n",
      "\n",
      "Number of Object Columns:  46\n",
      "\n",
      "\n",
      "Columns of type Int or Float:\n",
      "\n",
      " ['1stFlrSF', '2ndFlrSF', '3SsnPorch', 'BedroomAbvGr', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtUnfSF', 'EnclosedPorch', 'Fireplaces', 'FullBath', 'GarageArea', 'GarageCars', 'GarageYrBlt', 'GrLivArea', 'HalfBath', 'Id', 'KitchenAbvGr', 'LotArea', 'LotFrontage', 'LowQualFinSF', 'MasVnrArea', 'MiscVal', 'MoSold', 'OpenPorchSF', 'OverallQual', 'PID', 'PoolArea', 'SalePrice', 'ScreenPorch', 'TotRmsAbvGrd', 'TotalBsmtSF', 'WoodDeckSF', 'YearBuilt', 'YearRemod/Add', 'YrSold']\n",
      "\n",
      "\n",
      "Number of Numeric Columns:  37\n"
     ]
    }
   ],
   "source": [
    "object_col_list = []\n",
    "numeric_col_list = [] \n",
    "\n",
    "\n",
    "for k,v in enumerate(train_test_merged.dtypes):\n",
    "    if v == np.object: \n",
    "        object_col_list.append(train_test_merged.columns[k])\n",
    "    else: \n",
    "        numeric_col_list.append(train_test_merged.columns[k])\n",
    "\n",
    "print ('Columns of type Object:\\n\\n',  object_col_list)\n",
    "print ('\\n')\n",
    "print ('Number of Object Columns: ', len(object_col_list))\n",
    "print ('\\n')\n",
    "print ('Columns of type Int or Float:\\n\\n',  numeric_col_list)\n",
    "print ('\\n')\n",
    "print ('Number of Numeric Columns: ', len(numeric_col_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Columns in the Merged Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alley             object\n",
       "BsmtCond          object\n",
       "BsmtExposure      object\n",
       "BsmtFinSF1       float64\n",
       "BsmtFinSF2       float64\n",
       "BsmtFinType1      object\n",
       "BsmtFinType2      object\n",
       "BsmtFullBath     float64\n",
       "BsmtHalfBath     float64\n",
       "BsmtQual          object\n",
       "BsmtUnfSF        float64\n",
       "Electrical        object\n",
       "Fence             object\n",
       "FireplaceQu       object\n",
       "GarageArea       float64\n",
       "GarageCars       float64\n",
       "GarageCond        object\n",
       "GarageFinish      object\n",
       "GarageQual        object\n",
       "GarageType        object\n",
       "GarageYrBlt      float64\n",
       "LotFrontage      float64\n",
       "MasVnrArea       float64\n",
       "MasVnrType        object\n",
       "MiscFeature       object\n",
       "PoolQC            object\n",
       "SaleCondition     object\n",
       "SalePrice        float64\n",
       "TotalBsmtSF      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Reviewing the null columns types in the merged dataset'''\n",
    "train_test_merged[null_col_list].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for the Categorical Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Function to impute the categorical columns with the Most Frequent Values'''\n",
    "\n",
    "def categorical_imputer(col):\n",
    "    print ('Null Count in ', '\"',  cols ,'\"',  'column Pre Transform: ' , train_test_merged[col].isnull().sum())\n",
    "    train_test_merged[col].fillna(value = train_test_merged[col].value_counts().index[0], inplace=True)\n",
    "    print ('Null Count in ', '\"',  cols ,'\"',  'column Post Transform: ' , train_test_merged[col].isnull().sum())\n",
    "    print ('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Count in  \" Alley \" column Pre Transform:  2732\n",
      "Null Count in  \" Alley \" column Post Transform:  0\n",
      "\n",
      "\n",
      "Null Count in  \" BsmtCond \" column Pre Transform:  80\n",
      "Null Count in  \" BsmtCond \" column Post Transform:  0\n",
      "\n",
      "\n",
      "Null Count in  \" BsmtExposure \" column Pre Transform:  83\n",
      "Null Count in  \" BsmtExposure \" column Post Transform:  0\n",
      "\n",
      "\n",
      "Null Count in  \" BsmtFinType1 \" column Pre Transform:  80\n",
      "Null Count in  \" BsmtFinType1 \" column Post Transform:  0\n",
      "\n",
      "\n",
      "Null Count in  \" BsmtFinType2 \" column Pre Transform:  81\n",
      "Null Count in  \" BsmtFinType2 \" column Post Transform:  0\n",
      "\n",
      "\n",
      "Null Count in  \" BsmtQual \" column Pre Transform:  80\n",
      "Null Count in  \" BsmtQual \" column Post Transform:  0\n",
      "\n",
      "\n",
      "Null Count in  \" Electrical \" column Pre Transform:  1\n",
      "Null Count in  \" Electrical \" column Post Transform:  0\n",
      "\n",
      "\n",
      "Null Count in  \" Fence \" column Pre Transform:  2358\n",
      "Null Count in  \" Fence \" column Post Transform:  0\n",
      "\n",
      "\n",
      "Null Count in  \" FireplaceQu \" column Pre Transform:  1422\n",
      "Null Count in  \" FireplaceQu \" column Post Transform:  0\n",
      "\n",
      "\n",
      "Null Count in  \" GarageCond \" column Pre Transform:  159\n",
      "Null Count in  \" GarageCond \" column Post Transform:  0\n",
      "\n",
      "\n",
      "Null Count in  \" GarageFinish \" column Pre Transform:  159\n",
      "Null Count in  \" GarageFinish \" column Post Transform:  0\n",
      "\n",
      "\n",
      "Null Count in  \" GarageQual \" column Pre Transform:  159\n",
      "Null Count in  \" GarageQual \" column Post Transform:  0\n",
      "\n",
      "\n",
      "Null Count in  \" GarageType \" column Pre Transform:  157\n",
      "Null Count in  \" GarageType \" column Post Transform:  0\n",
      "\n",
      "\n",
      "Null Count in  \" MasVnrType \" column Pre Transform:  23\n",
      "Null Count in  \" MasVnrType \" column Post Transform:  0\n",
      "\n",
      "\n",
      "Null Count in  \" MiscFeature \" column Pre Transform:  2824\n",
      "Null Count in  \" MiscFeature \" column Post Transform:  0\n",
      "\n",
      "\n",
      "Null Count in  \" PoolQC \" column Pre Transform:  2917\n",
      "Null Count in  \" PoolQC \" column Post Transform:  0\n",
      "\n",
      "\n",
      "Null Count in  \" SaleCondition \" column Pre Transform:  879\n",
      "Null Count in  \" SaleCondition \" column Post Transform:  0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Using the for loop on the null columns and imputing the object columns with the most frequent value'''\n",
    "\n",
    "for cols in null_col_list: \n",
    "    if train_test_merged[cols].dtypes == 'object': \n",
    "        categorical_imputer(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The result above gives the entire list of categorical columns that were imputed using the most frequent value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BsmtFinSF1', 'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtUnfSF',\n",
       "       'GarageArea', 'GarageCars', 'GarageYrBlt', 'LotFrontage', 'MasVnrArea',\n",
       "       'SalePrice', 'TotalBsmtSF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Validating the remaning null columms'''\n",
    "\n",
    "train_test_merged.columns[train_test_merged.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On quick review, these look like numerical columns. We are going to impute these columns in the subsequent cells using the median imputer from the Pre-Processing module**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Dummies for the Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2930, 286)\n"
     ]
    }
   ],
   "source": [
    "train_test_merge_dummies = pd.get_dummies(train_test_merged, drop_first=True)\n",
    "print (train_test_merge_dummies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_to_exclude = ['PID', 'SaleCondition', 'SalePrice', 'Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_merged.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Setting the list of columns to be included in the Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1stFlrSF', '2ndFlrSF', '3SsnPorch', 'BedroomAbvGr', 'BsmtFinSF1']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_include= []\n",
    "for columns in list(train_test_merge_dummies.columns): \n",
    "    if columns not in cols_to_exclude: \n",
    "        cols_to_include.append(columns)\n",
    "cols_to_include[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of columns to be included is stored in the **cols_to_include** list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating the list of Null Columns in the Dummied Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BsmtFinSF1', 'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtUnfSF',\n",
       "       'GarageArea', 'GarageCars', 'GarageYrBlt', 'LotFrontage', 'MasVnrArea',\n",
       "       'SalePrice', 'TotalBsmtSF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_merge_dummies.columns[train_test_merge_dummies.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the columns are numerical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the test and training sets to build the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Setting up the Predictors (X) and the Target (Y) variables on the Training Set'''\n",
    "\n",
    "X_new_training_data = train_test_merge_dummies.loc[train_test_merge_dummies['source_Train'] == 1,cols_to_include]\n",
    "y_new_training_data = train_test_merge_dummies.loc[train_test_merge_dummies['source_Train'] == 1,'SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Setting up the predictors (X) on the Test Set'''\n",
    "\n",
    "X_new_test_data = train_test_merge_dummies.loc[train_test_merge_dummies['source_Train'] == 0,cols_to_include]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new_training_data.drop(['GarageYrBlt', 'LotFrontage', 'MasVnrArea','Id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_new_test_data.drop(['GarageYrBlt', 'LotFrontage', 'MasVnrArea', 'Id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the Shape of the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2051, 283)\n",
      "(2051,)\n",
      "(879, 283)\n"
     ]
    }
   ],
   "source": [
    "print (X_new_training_data.shape)\n",
    "print (y_new_training_data.shape)\n",
    "print (X_new_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new_training_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def numeric_col_extractor(df):\n",
    "#     for k,v in enumerate(df.dtypes):\n",
    "#         if v == 'int64' or v == 'float64' :\n",
    "#             numeric_col_list_dummies.append(df.columns[k])\n",
    "#         else: \n",
    "#             continue\n",
    "#     return numeric_col_list_dummies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# num_cols = numeric_col_extractor(X_new_training_data)\n",
    "# numeric_df = X_new_training_data.loc[:,num_cols]\n",
    "# im = Imputer(strategy = 'median')\n",
    "# transformed_train = im.fit_transform(numeric_df)\n",
    "\n",
    "# num_test_cols = numeric_col_extractor(X_new_training_data)\n",
    "# numeric_test_df = X_new_test_data.loc[:,num_test_cols]\n",
    "# transformed_test = im.transform(numeric_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Median Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "median_imputer = Imputer(strategy='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Count of Null Numeric Columns in the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Null Numeric Columns that needs to be addressed:  11\n",
      "\n",
      "Here is the list: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['BsmtFinSF1', 'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtUnfSF',\n",
       "       'GarageArea', 'GarageCars', 'GarageYrBlt', 'LotFrontage', 'MasVnrArea',\n",
       "       'TotalBsmtSF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Numeric Columns in the Training set that needs to be addressed. In other words, we are going to apply the median imputer on all the numerical columns in the training set'''\n",
    "\n",
    "print ('Total Number of Null Numeric Columns that needs to be addressed: ', len(X_new_training_data.columns[X_new_training_data.isnull().sum()>0]))\n",
    "\n",
    "print ('\\nHere is the list: ')\n",
    "\n",
    "X_new_training_data.columns[X_new_training_data.isnull().sum()>0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting a sense of numerical columns in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1stFlrSF', '2ndFlrSF', '3SsnPorch', 'BedroomAbvGr', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtUnfSF', 'EnclosedPorch', 'Fireplaces', 'FullBath', 'GarageArea', 'GarageCars', 'GarageYrBlt', 'GrLivArea', 'HalfBath', 'KitchenAbvGr', 'LotArea', 'LotFrontage', 'LowQualFinSF', 'MasVnrArea', 'MiscVal', 'MoSold', 'OpenPorchSF', 'OverallQual', 'PoolArea', 'ScreenPorch', 'TotRmsAbvGrd', 'TotalBsmtSF', 'WoodDeckSF', 'YearBuilt', 'YearRemod/Add', 'YrSold']\n"
     ]
    }
   ],
   "source": [
    "numeric_col_list_dummies=[]\n",
    "for k,v in enumerate(X_new_training_data.dtypes):\n",
    "    if v == 'int64' or v == 'float64' : \n",
    "        numeric_col_list_dummies.append(X_new_training_data.columns[k])\n",
    "\n",
    "    else: \n",
    "        continue\n",
    "print (numeric_col_list_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# '''Imputing all the numeric colums in X_Train'''\n",
    "# for cols in numeric_col_list_dummies:\n",
    "#     X_new_training_data[cols] = median_imputer.fit_transform(X_new_training_data[[cols]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing the Null Columns with the Median Values using the Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "BsmtFinSF1_fit = median_imputer.fit(X_new_training_data[['BsmtFinSF1']])\n",
    "X_new_training_data['BsmtFinSF1'] = BsmtFinSF1_fit.transform(X_new_training_data[['BsmtFinSF1']])\n",
    "\n",
    "BsmtFinSF2_fit = median_imputer.fit(X_new_training_data[['BsmtFinSF2']])\n",
    "X_new_training_data['BsmtFinSF2'] = BsmtFinSF2_fit.transform(X_new_training_data[['BsmtFinSF2']])\n",
    "\n",
    "BsmtFullBath_fit = median_imputer.fit(X_new_training_data[['BsmtFullBath']])\n",
    "X_new_training_data['BsmtFullBath'] = BsmtFullBath_fit.transform(X_new_training_data[['BsmtFullBath']])\n",
    "\n",
    "BsmtHalfBath_fit = median_imputer.fit(X_new_training_data[['BsmtHalfBath']])\n",
    "X_new_training_data['BsmtHalfBath'] = BsmtHalfBath_fit.transform(X_new_training_data[['BsmtHalfBath']])\n",
    "\n",
    "BsmtUnfSF_fit = median_imputer.fit(X_new_training_data[['BsmtUnfSF']])\n",
    "X_new_training_data['BsmtUnfSF'] = BsmtUnfSF_fit.transform(X_new_training_data[['BsmtUnfSF']])\n",
    "\n",
    "GarageArea_fit = median_imputer.fit(X_new_training_data[['GarageArea']])\n",
    "X_new_training_data['GarageArea'] = GarageArea_fit.transform(X_new_training_data[['GarageArea']])\n",
    "\n",
    "GarageCars_fit = median_imputer.fit(X_new_training_data[['GarageCars']])\n",
    "X_new_training_data['GarageCars'] = GarageCars_fit.transform(X_new_training_data[['GarageCars']])\n",
    "\n",
    "GarageYrBlt_fit = median_imputer.fit(X_new_training_data[['GarageYrBlt']])\n",
    "X_new_training_data['GarageYrBlt'] = GarageYrBlt_fit.transform(X_new_training_data[['GarageYrBlt']])\n",
    "\n",
    "LotFrontage_fit = median_imputer.fit(X_new_training_data[['LotFrontage']])\n",
    "X_new_training_data['LotFrontage'] = LotFrontage_fit.transform(X_new_training_data[['LotFrontage']])\n",
    "\n",
    "MasVnrArea_fit = median_imputer.fit(X_new_training_data[['MasVnrArea']])\n",
    "X_new_training_data['MasVnrArea'] = MasVnrArea_fit.transform(X_new_training_data[['MasVnrArea']])\n",
    "\n",
    "TotalBsmtSF_fit = median_imputer.fit(X_new_training_data[['TotalBsmtSF']])\n",
    "X_new_training_data['TotalBsmtSF'] = TotalBsmtSF_fit.transform(X_new_training_data[['TotalBsmtSF']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above imputation should probably be carried out in a loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Validating to see if there are any null values in the predictors within the training set'''\n",
    "\n",
    "X_new_training_data.columns[X_new_training_data.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Validating to see if there are any null values in the Target Variables within the training set'''\n",
    "\n",
    "y_new_training_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the predictors and the targets in the dataset dont have any null values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Multiple Linear Regression '''\n",
    "\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Fitting the Model on the Training Set'''\n",
    "\n",
    "lr.fit(X_new_training_data, y_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444094662289878"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Scoring the Model on the Training Set'''\n",
    "\n",
    "lr.score(X_new_training_data, y_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Predicting the Training Values '''\n",
    "\n",
    "y_train_predicted = lr.predict(X_new_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the model on to Test Set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the list of null columns in the Test Set that will require imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GarageYrBlt', 'LotFrontage', 'MasVnrArea'], dtype='object')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_test_data.columns[X_new_test_data.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns *'GarageYrBlt', 'LotFrontage', 'MasVnrArea'* needs imputation from the training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new_test_data['GarageYrBlt'] = GarageYrBlt_fit.transform(X_new_test_data[['GarageYrBlt']])\n",
    "\n",
    "X_new_test_data['LotFrontage'] = LotFrontage_fit.transform(X_new_test_data[['LotFrontage']])\n",
    "\n",
    "X_new_test_data['MasVnrArea'] = MasVnrArea_fit.transform(X_new_test_data[['MasVnrArea']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Performing validation to see if there are any more null values'''\n",
    "X_new_test_data.columns[X_new_test_data.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected after the imputation there are no more null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the value of the Target Variable on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = lr.predict(X_new_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 132434.44175261,  254158.01500878,  193002.24266482,\n",
       "        106105.24980435,  269366.29379859])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Reviewing the first five values of the Predicted set'''\n",
    "y_predicted[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 879 entries, 0 to 878\n",
      "Data columns (total 2 columns):\n",
      "Id           879 non-null int64\n",
      "SalePrice    879 non-null float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 13.8 KB\n"
     ]
    }
   ],
   "source": [
    "'''Creating a Dataframe of the predicted values. This will be used to create the CSV file'''\n",
    "\n",
    "d = {'Id': test_raw['Id'], 'SalePrice': y_predicted}\n",
    "predicted_df= pd.DataFrame(d)\n",
    "predicted_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV File Creation with the Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_df.to_csv('ac_basic_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Mean Square Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error:  18682.769015\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_new_training_data, y_train_predicted))\n",
    "print ('Root Mean Square Error: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.05263106534\n"
     ]
    }
   ],
   "source": [
    "'''Using the RidgeCV Approach to get the Optimal Alpha Value'''\n",
    "\n",
    "ridge_alphas = np.logspace(0, 5, 200)\n",
    "\n",
    "optimal_ridge = RidgeCV(alphas=ridge_alphas, cv=10)\n",
    "optimal_ridge.fit(X_new_training_data, y_new_training_data)\n",
    "\n",
    "print(optimal_ridge.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.89090039  0.86367156  0.90952369  0.91556022  0.60831713  0.90414927\n",
      "  0.90775448  0.89704457  0.89179566  0.72519327]\n",
      "0.851391023175\n"
     ]
    }
   ],
   "source": [
    "'''Using the Optimal Alpha Value calculated in the previous step to perform a Ridge Regression'''\n",
    "\n",
    "ridge = Ridge(alpha=optimal_ridge.alpha_)\n",
    "ridge_scores = cross_val_score(ridge, X_new_training_data, y_new_training_data, cv=10)\n",
    "\n",
    "print(ridge_scores)\n",
    "print(np.mean(ridge_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=5.0526310653356807, copy_X=True, fit_intercept=True,\n",
       "   max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "   tol=0.001)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Fitting the Model'''\n",
    "\n",
    "ridge.fit(X_new_training_data, y_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91620867193542199"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Scoring the Model'''\n",
    "ridge.score(X_new_training_data, y_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Predicting on the Training Set'''\n",
    "y_ridge_train_predict = ridge.predict(X_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Predicting on the Test Set'''\n",
    "y_ridge_test_predict = ridge.predict(X_new_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 879 entries, 0 to 878\n",
      "Data columns (total 2 columns):\n",
      "Id           879 non-null int64\n",
      "SalePrice    879 non-null float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 13.8 KB\n"
     ]
    }
   ],
   "source": [
    "'''Creating a Dataframe of the predicted values. This will be used to create the CSV file'''\n",
    "\n",
    "y_ridge_test_predict = ridge.predict(X_new_test_data)\n",
    "d = {'Id': test_raw['Id'], 'SalePrice': y_ridge_test_predict}\n",
    "predicted_df= pd.DataFrame(d)\n",
    "predicted_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV File Creation with the Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_df.to_csv('ac_ridge_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Mean Square Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error:  22937.1977774\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_new_training_data, y_ridge_train_predict))\n",
    "print ('Root Mean Square Error: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Alpha:  2.08540113522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajinthchristudas/anaconda/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=1.360e+01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.825e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/ajinthchristudas/anaconda/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=2.079e+00, with an active set of 225 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/ajinthchristudas/anaconda/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=2.062e+00, with an active set of 225 regressors, and the smallest cholesky pivot element being 8.297e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/ajinthchristudas/anaconda/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 262 iterations, alpha=2.054e+00, previous alpha=1.957e+00, with an active set of 225 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "'''Calculating the Optimal Value of Alpha using the LassoLarsIC Method'''\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(X_new_training_data, y_new_training_data)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "print ('Optimal Alpha: ', alpha_aic_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajinthchristudas/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=2.0854011352200117, copy_X=True, fit_intercept=True,\n",
       "   max_iter=8000, normalize=False, positive=False, precompute=False,\n",
       "   random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Fitting the Model'''\n",
    "\n",
    "lasso = Lasso(max_iter=8000, alpha=alpha_aic_)\n",
    "lasso.fit(X_new_training_data, y_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94388551546838118"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Scoring the Model'''\n",
    "\n",
    "lasso.score(X_new_training_data, y_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Predicting on the Test Set'''\n",
    "y_lasso_test_predict = lasso.predict(X_new_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Predicting on the Train Set'''\n",
    "y_lasso_train_predict = lasso.predict(X_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 879 entries, 0 to 878\n",
      "Data columns (total 2 columns):\n",
      "Id           879 non-null int64\n",
      "SalePrice    879 non-null float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 13.8 KB\n"
     ]
    }
   ],
   "source": [
    "'''Creating a Dataframe of the predicted values. This will be used to create the CSV file'''\n",
    "\n",
    "d = {'Id': test_raw['Id'], 'SalePrice': y_lasso_test_predict}\n",
    "predicted_df= pd.DataFrame(d)\n",
    "predicted_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV File Creation from the Basic Lasso Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_df.to_csv('ac_lasso_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Mean Square Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error:  18770.6067548\n"
     ]
    }
   ],
   "source": [
    "# Root Mean Square Error \n",
    "rmse = np.sqrt(mean_squared_error(y_new_training_data, y_lasso_train_predict))\n",
    "print ('Root Mean Square Error: ', rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensCV = ElasticNetCV(alphas=[0.0001, 0.0005, 0.001, 0.01, 0.1, 1, 2, 10],\\\n",
    "                       l1_ratio=[.01, .1, .5, .9, .99], max_iter=5000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of ElasticNetCV(alphas=[0.0001, 0.0005, 0.001, 0.01, 0.1, 1, 2, 10], copy_X=True,\n",
       "       cv=None, eps=0.001, fit_intercept=True,\n",
       "       l1_ratio=[0.01, 0.1, 0.5, 0.9, 0.99], max_iter=5000, n_alphas=100,\n",
       "       n_jobs=1, normalize=False, positive=False, precompute='auto',\n",
       "       random_state=None, selection='cyclic', tol=0.0001, verbose=0)>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensCV.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajinthchristudas/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/ajinthchristudas/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElasticNetCV(alphas=[0.0001, 0.0005, 0.001, 0.01, 0.1, 1, 2, 10], copy_X=True,\n",
       "       cv=None, eps=0.001, fit_intercept=True,\n",
       "       l1_ratio=[0.01, 0.1, 0.5, 0.9, 0.99], max_iter=5000, n_alphas=100,\n",
       "       n_jobs=1, normalize=False, positive=False, precompute='auto',\n",
       "       random_state=None, selection='cyclic', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Fitting the Basic Model'''\n",
    "\n",
    "ensCV.fit(X_new_training_data, y_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92012928479840117"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Scoring the Basic Model'''\n",
    "\n",
    "ensCV.score(X_new_training_data, y_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Predicting on the Train'''\n",
    "\n",
    "y_enscv_train_predict = ensCV.predict(X_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 879 entries, 0 to 878\n",
      "Data columns (total 2 columns):\n",
      "Id           879 non-null int64\n",
      "SalePrice    879 non-null float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 13.8 KB\n"
     ]
    }
   ],
   "source": [
    "'''Creating a Dataframe of the predicted values. This will be used to create the CSV file'''\n",
    "\n",
    "y_enscv_test_predict = ensCV.predict(X_new_test_data)\n",
    "\n",
    "d = {'Id': test_raw['Id'], 'SalePrice': y_enscv_test_predict}\n",
    "predicted_df= pd.DataFrame(d)\n",
    "predicted_df.info()\n",
    "\n",
    "predicted_df.to_csv('ac_ens_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root Mean Square Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error:  22394.1513503\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_new_training_data, y_enscv_train_predict))\n",
    "print ('Root Mean Square Error: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using RFE to perform Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfe = RFE(gb, n_features_to_select=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SelectorMixin.get_support of RFE(estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.05, loss='ls', max_depth=8, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "             min_samples_leaf=8, min_samples_split=6,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "             presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "             warm_start=False),\n",
       "  n_features_to_select=100, step=1, verbose=2)>"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.get_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 280 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 278 features.\n",
      "Fitting estimator with 277 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 275 features.\n",
      "Fitting estimator with 274 features.\n",
      "Fitting estimator with 273 features.\n",
      "Fitting estimator with 272 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 270 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 268 features.\n",
      "Fitting estimator with 267 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 264 features.\n",
      "Fitting estimator with 263 features.\n",
      "Fitting estimator with 262 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 260 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 258 features.\n",
      "Fitting estimator with 257 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 255 features.\n",
      "Fitting estimator with 254 features.\n",
      "Fitting estimator with 253 features.\n",
      "Fitting estimator with 252 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 250 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 248 features.\n",
      "Fitting estimator with 247 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 245 features.\n",
      "Fitting estimator with 244 features.\n",
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 242 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 240 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 238 features.\n",
      "Fitting estimator with 237 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 235 features.\n",
      "Fitting estimator with 234 features.\n",
      "Fitting estimator with 233 features.\n",
      "Fitting estimator with 232 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 230 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 228 features.\n",
      "Fitting estimator with 227 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 225 features.\n",
      "Fitting estimator with 224 features.\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 220 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 218 features.\n",
      "Fitting estimator with 217 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 215 features.\n",
      "Fitting estimator with 214 features.\n",
      "Fitting estimator with 213 features.\n",
      "Fitting estimator with 212 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 210 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 208 features.\n",
      "Fitting estimator with 207 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 205 features.\n",
      "Fitting estimator with 204 features.\n",
      "Fitting estimator with 203 features.\n",
      "Fitting estimator with 202 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 200 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 198 features.\n",
      "Fitting estimator with 197 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 195 features.\n",
      "Fitting estimator with 194 features.\n",
      "Fitting estimator with 193 features.\n",
      "Fitting estimator with 192 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 190 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 188 features.\n",
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 185 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 182 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 180 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 177 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 174 features.\n",
      "Fitting estimator with 173 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 170 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 168 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 165 features.\n",
      "Fitting estimator with 164 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 162 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 158 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 153 features.\n",
      "Fitting estimator with 152 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 150 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 144 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 140 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 138 features.\n",
      "Fitting estimator with 137 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 134 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 132 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 128 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 122 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 120 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 117 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 114 features.\n",
      "Fitting estimator with 113 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 110 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 108 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98931146572853856"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.fit(X_new_training_data, y_new_training_data)\n",
    "rfe.score(X_new_training_data, y_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rfe.n_features_to_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1stFlrSF kept!\n",
      "2ndFlrSF kept!\n",
      "BedroomAbvGr kept!\n",
      "BsmtFinSF1 kept!\n",
      "BsmtFinSF2 kept!\n",
      "BsmtFullBath kept!\n",
      "BsmtUnfSF kept!\n",
      "EnclosedPorch kept!\n",
      "Fireplaces kept!\n",
      "FullBath kept!\n",
      "GarageArea kept!\n",
      "GarageCars kept!\n",
      "GrLivArea kept!\n",
      "HalfBath kept!\n",
      "Id kept!\n",
      "LotArea kept!\n",
      "LowQualFinSF kept!\n",
      "MoSold kept!\n",
      "OpenPorchSF kept!\n",
      "OverallQual kept!\n",
      "ScreenPorch kept!\n",
      "TotRmsAbvGrd kept!\n",
      "TotalBsmtSF kept!\n",
      "WoodDeckSF kept!\n",
      "YearBuilt kept!\n",
      "YearRemod/Add kept!\n",
      "YrSold kept!\n",
      "BsmtCond_Fa kept!\n",
      "BsmtCond_Gd kept!\n",
      "BsmtCond_TA kept!\n",
      "BsmtExposure_Gd kept!\n",
      "BsmtExposure_No kept!\n",
      "BsmtFinType1_GLQ kept!\n",
      "BsmtFinType1_Rec kept!\n",
      "BsmtQual_Gd kept!\n",
      "BsmtQual_TA kept!\n",
      "CentralAir_Y kept!\n",
      "Condition1_Feedr kept!\n",
      "Condition1_Norm kept!\n",
      "ExterCond_Fa kept!\n",
      "ExterCond_TA kept!\n",
      "ExterQual_Gd kept!\n",
      "ExterQual_TA kept!\n",
      "Exterior1st_BrkFace kept!\n",
      "Exterior1st_MetalSd kept!\n",
      "Exterior1st_VinylSd kept!\n",
      "Exterior1st_Wd Sdng kept!\n",
      "Exterior2nd_HdBoard kept!\n",
      "Exterior2nd_MetalSd kept!\n",
      "Exterior2nd_VinylSd kept!\n",
      "Exterior2nd_Wd Sdng kept!\n",
      "FireplaceQu_Gd kept!\n",
      "Foundation_CBlock kept!\n",
      "Foundation_PConc kept!\n",
      "Functional_Typ kept!\n",
      "GarageFinish_RFn kept!\n",
      "GarageFinish_Unf kept!\n",
      "GarageType_Attchd kept!\n",
      "GarageType_CarPort kept!\n",
      "GarageType_Detchd kept!\n",
      "Heating_GasA kept!\n",
      "HeatingQC_TA kept!\n",
      "KitchenQual_Gd kept!\n",
      "KitchenQual_TA kept!\n",
      "LandContour_HLS kept!\n",
      "LandContour_Low kept!\n",
      "LandContour_Lvl kept!\n",
      "LandSlope_Mod kept!\n",
      "LotConfig_CulDSac kept!\n",
      "LotConfig_Inside kept!\n",
      "LotShape_Reg kept!\n",
      "MSSubClass_30 kept!\n",
      "MSSubClass_60 kept!\n",
      "MSZoning_FV kept!\n",
      "MSZoning_RL kept!\n",
      "MSZoning_RM kept!\n",
      "MasVnrType_BrkFace kept!\n",
      "MasVnrType_None kept!\n",
      "MasVnrType_Stone kept!\n",
      "Neighborhood_BrkSide kept!\n",
      "Neighborhood_CollgCr kept!\n",
      "Neighborhood_Crawfor kept!\n",
      "Neighborhood_Edwards kept!\n",
      "Neighborhood_NridgHt kept!\n",
      "Neighborhood_OldTown kept!\n",
      "Neighborhood_SawyerW kept!\n",
      "Neighborhood_Somerst kept!\n",
      "Neighborhood_StoneBr kept!\n",
      "OverallCond_3 kept!\n",
      "OverallCond_4 kept!\n",
      "OverallCond_5 kept!\n",
      "OverallCond_6 kept!\n",
      "OverallCond_7 kept!\n",
      "OverallCond_8 kept!\n",
      "PavedDrive_Y kept!\n",
      "RoofStyle_Gable kept!\n",
      "SaleCondition_Normal kept!\n",
      "SaleCondition_Partial kept!\n",
      "SaleType_New kept!\n",
      "SaleType_WD  kept!\n"
     ]
    }
   ],
   "source": [
    "rfe_col_list = []\n",
    "for col, keep in zip(X_new_training_data.columns, rfe.support_):\n",
    "    if keep == True:\n",
    "        rfe_col_list.append(col)\n",
    "        print(col, 'kept!')\n",
    "    else: \n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 879 entries, 0 to 878\n",
      "Data columns (total 2 columns):\n",
      "Id           879 non-null int64\n",
      "SalePrice    879 non-null float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 20.6 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8192.187796094915"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(learning_rate=0.05, max_depth=8, min_samples_leaf=8,\\\n",
    "                               min_samples_split=6, loss='ls', alpha=0.9)\n",
    "gb.fit(X_new_training_data[rfe_col_list], y_new_training_data)\n",
    "gb.score(X_new_training_data[rfe_col_list], y_new_training_data)\n",
    "\n",
    "\n",
    "y_gb_train_predict = gb.predict(X_new_training_data[rfe_col_list])\n",
    "y_gb_test_predict = gb.predict(X_new_test_data[rfe_col_list])\n",
    "\n",
    "d = {'Id': X_new_test_data['Id'], 'SalePrice': y_gb_test_predict}\n",
    "predicted_df= pd.DataFrame(d)\n",
    "predicted_df.info()\n",
    "\n",
    "predicted_df.to_csv('ac_gb_predictions.csv', index=False)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_new_training_data, y_gb_train_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost Ensemble Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score 0.915720964935\n",
      "best params {'max_depth': 3, 'max_features': 100}\n",
      "test score 0.960013365164\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gb = GradientBoostingRegressor()\n",
    "gb_params = {\n",
    "#     'n_estimators': [11000],\n",
    "    'max_depth': [2,3,4,5,6,7,8,9,10],\n",
    "    'max_features': [4,6,8,10,100,150, 200, 250, 'sqrt']\n",
    "}\n",
    "gb_model = GridSearchCV(gb, param_grid=gb_params, n_jobs=-1)\n",
    "gb_model.fit(X_new_training_data, y_new_training_data)\n",
    "print('best score', gb_model.best_score_)\n",
    "print('best params', gb_model.best_params_)\n",
    "print('test score', gb_model.score(X_new_training_data, y_new_training_data))\n",
    "\n",
    "# y_gb_train_predict = GBest.predict(X_new_training_data)\n",
    "# y_gb_test_predict = gb_model.predict(X_new_test_data)\n",
    "\n",
    "# d = {'Id': X_new_test_data['Id'], 'SalePrice': y_gb_test_predict}\n",
    "# predicted_df= pd.DataFrame(d)\n",
    "# predicted_df.info()\n",
    "\n",
    "# predicted_df.to_csv('ac_gb_predictions.csv', index=False)\n",
    "\n",
    "# np.sqrt(mean_squared_error(y_new_training_data, y_gb_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MSE of 26,195 - also submitted on Kaggle \n",
    "# GBest = GradientBoostingRegressor(n_estimators=8000, learning_rate=0.05, max_depth=4, max_features='sqrt',\n",
    "#                                                min_samples_leaf=8, min_samples_split=8, loss='huber', alpha=0.95)\n",
    "\n",
    "# MSE Of 28k but on the Train it was close to 2.3K \n",
    "# GBest = GradientBoostingRegressor(n_estimators=8000, learning_rate=0.05, max_depth=4, max_features=150,\n",
    "#                                                min_samples_leaf=8, min_samples_split=8, loss='huber', alpha=0.99)\n",
    "\n",
    "# MSE Of 28k, score of 0.9999, and score of 0.022 in train\n",
    "# GBest = GradientBoostingRegressor(n_estimators=9000, learning_rate=0.05, max_depth=8, max_features=150,\n",
    "#                                                min_samples_leaf=8, min_samples_split=6, loss='ls', alpha=0.9)\n",
    "\n",
    "\n",
    "GBest = GradientBoostingRegressor(n_estimators=30000, learning_rate=0.05, max_depth=4, max_features='sqrt',\n",
    "                                               min_samples_leaf=20, min_samples_split=15, loss='huber', alpha=0.8)\n",
    "\n",
    "\n",
    "# GBest = GradientBoostingRegressor(n_estimators=30000, learning_rate=0.05,\n",
    "#                                    max_depth=4, max_features='sqrt',\n",
    "#                                    min_samples_leaf=15, min_samples_split=10, \n",
    "#                                    loss='huber')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.999, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.05, loss='huber', max_depth=4,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=20,\n",
       "             min_samples_split=15, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=30000, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 1165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBest.fit(X_new_training_data, y_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99997474711539891"
      ]
     },
     "execution_count": 1166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBest.score(X_new_training_data, y_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 879 entries, 0 to 878\n",
      "Data columns (total 2 columns):\n",
      "Id           879 non-null int64\n",
      "SalePrice    879 non-null float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 13.8 KB\n"
     ]
    }
   ],
   "source": [
    "y_gb_train_predict = GBest.predict(X_new_training_data)\n",
    "y_gb_test_predict = GBest.predict(X_new_test_data)\n",
    "\n",
    "d = {'Id': test_raw['Id'], 'SalePrice': y_gb_test_predict}\n",
    "predicted_df= pd.DataFrame(d)\n",
    "predicted_df.info()\n",
    "\n",
    "predicted_df.to_csv('ac_gb_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398.19547403520789"
      ]
     },
     "execution_count": 1168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_new_training_data, y_gb_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Average of two models\n",
    "# Final_labels = (np.exp(GBest.predict(X_new_test_data)) + np.exp(ensCV.predict(X_new_test_data))) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame({'Id': X_new_test_data['Id'], 'SalePrice': Final_labels}).to_csv('ac_combinded.csv', index =False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_new_training_data.Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import make_pipeline\n",
    "# pipeline = make_pipeline(StandardScaler(), gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline.fit(X_new_training_data, y_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline.score(X_new_training_data, y_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline.predict(X_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.sqrt(mean_squared_error(y_new_training_data, pipeline.predict(X_new_training_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86807357339283664"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestRegressor(n_estimators=8000, max_depth=4, n_jobs=-1)\n",
    "clf.fit(X_new_training_data, y_new_training_data)\n",
    "clf.score(X_new_training_data, y_new_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4817.3763622222741"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rf_train_predict = clf.predict(X_new_training_data)\n",
    "y_rf_test_predict = clf.predict(X_new_test_data)\n",
    "np.sqrt(mean_squared_error(y_new_training_data, y_gb_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rfe=RFECV(gb, n_jobs = -1, verbose=1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
